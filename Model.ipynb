{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "SOQS_s2oDdOL"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import MaxPooling2D,concatenate,add,Conv2D,Dense,BatchNormalization,Concatenate,Input,Dropout,Maximum,Activation,Dense,Flatten,UpSampling2D,Conv2DTranspose,Add,Multiply,Lambda\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "NEBSHjivKqyD"
      },
      "outputs": [],
      "source": [
        "filters = 16 # bump upto 64 for better results?\n",
        "output_channels = 1\n",
        "width = 256\n",
        "height = 256\n",
        "input_channels = 1\n",
        "conv_layers = 2\n",
        "rr_layers = 2\n",
        "\n",
        "def recurrent_block(layer_input, filters, conv_layers=2, rr_layers=2):\n",
        "    convs = []\n",
        "    for i in range(conv_layers - 1):\n",
        "        a = Conv2D(filters, kernel_size=(3, 3), strides=(1, 1), padding='same')\n",
        "        convs.append(a)\n",
        "\n",
        "    d = layer_input\n",
        "    for i in range(len(convs)):\n",
        "        a = convs[i]\n",
        "        d = a(d)\n",
        "        d = BatchNormalization()(d)\n",
        "        d = Activation('relu')(d)\n",
        "\n",
        "    for j in range(rr_layers):\n",
        "        d = Add()([d, layer_input])\n",
        "        for i in range(len(convs)):\n",
        "            a = convs[i]\n",
        "            d = a(d)\n",
        "            d = BatchNormalization()(d)\n",
        "            d = Activation('relu')(d)\n",
        "\n",
        "    return d\n",
        "\n",
        "\n",
        "def RRCNN_block(layer_input, filters, conv_layers=2, rr_layers=2):\n",
        "    d = Conv2D(filters, kernel_size=(3, 3), strides=(1, 1), padding='same')(layer_input)\n",
        "    d1 = recurrent_block(d, filters, conv_layers=conv_layers, rr_layers=rr_layers)\n",
        "    return Add()([d, d1])\n",
        "\n",
        "\n",
        "def deconv2d(layer_input, filters):\n",
        "    u = Conv2DTranspose(filters, 2, strides=(2, 2), padding='same')(layer_input)\n",
        "    u = BatchNormalization()(u)\n",
        "    u = Activation('relu')(u)\n",
        "    return u\n",
        "\n",
        "\n",
        "inputs = Input(shape=(width, height, input_channels))\n",
        "\n",
        "\n",
        "conv1 = RRCNN_block(inputs, filters, conv_layers=conv_layers, rr_layers=rr_layers)\n",
        "pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "conv2 = RRCNN_block(pool1, filters * 2, conv_layers=conv_layers, rr_layers=rr_layers)\n",
        "pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "conv3 = RRCNN_block(pool2, filters * 4, conv_layers=conv_layers, rr_layers=rr_layers)\n",
        "pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "conv4 = RRCNN_block(pool3, filters * 8, conv_layers=conv_layers, rr_layers=rr_layers)\n",
        "pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
        "\n",
        "conv5 = RRCNN_block(pool4, filters * 16, conv_layers=conv_layers, rr_layers=rr_layers)\n",
        "\n",
        "\n",
        "conv6 = deconv2d(conv5, filters * 8)\n",
        "up6 = concatenate([conv6, conv4])\n",
        "up6 = RRCNN_block(up6, filters * 8, conv_layers=conv_layers, rr_layers=rr_layers)\n",
        "\n",
        "\n",
        "conv7 = Conv2DTranspose(filters * 4, 3, strides=(2, 2), padding='same')(up6)\n",
        "up7 = concatenate([conv7, conv3])\n",
        "up7 = RRCNN_block(up7, filters * 4, conv_layers=conv_layers, rr_layers=rr_layers)\n",
        "\n",
        "\n",
        "conv8 = Conv2DTranspose(filters * 2, 3, strides=(2, 2), padding='same')(up7)\n",
        "up8 = concatenate([conv8, conv2])\n",
        "up8 = RRCNN_block(up8, filters * 2, conv_layers=conv_layers, rr_layers=rr_layers)\n",
        "\n",
        "\n",
        "conv9 = Conv2DTranspose(filters, 3, strides=(2, 2), padding='same')(up8)\n",
        "up9 = concatenate([conv9, conv1])\n",
        "up9 = RRCNN_block(up9, filters, conv_layers=conv_layers, rr_layers=rr_layers)\n",
        "\n",
        "\n",
        "output_layer_noActi = Conv2D(output_channels, (1, 1), padding=\"same\", activation=None)(up9)\n",
        "outputs = Activation('sigmoid')(output_layer_noActi) # changed to sigmoid from softmax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2oGF8muVKyCc",
        "outputId": "38c1cd56-883c-44fe-e1f4-d87c5f249c6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 501ms/step - accuracy: 0.9997 - loss: 0.0024\n",
            "Epoch 2/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 508ms/step - accuracy: 0.9997 - loss: 0.0011\n",
            "Epoch 3/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 499ms/step - accuracy: 0.9997 - loss: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 497ms/step - accuracy: 0.9997 - loss: 9.1585e-04\n",
            "Epoch 5/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 496ms/step - accuracy: 0.9997 - loss: 9.1388e-04\n",
            "Epoch 6/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 501ms/step - accuracy: 0.9997 - loss: 9.7481e-04\n",
            "Epoch 7/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 500ms/step - accuracy: 0.9997 - loss: 9.1165e-04\n",
            "Epoch 8/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 498ms/step - accuracy: 0.9997 - loss: 8.7732e-04\n",
            "Epoch 9/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 498ms/step - accuracy: 0.9997 - loss: 8.0035e-04\n",
            "Epoch 10/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 497ms/step - accuracy: 0.9997 - loss: 8.0567e-04\n"
          ]
        }
      ],
      "source": [
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "model.count_params()\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "model.input\n",
        "\n",
        "import glob\n",
        "\n",
        "# Load all npy files in the train_y folder\n",
        "npy_files = glob.glob('train_x/*.npy')\n",
        "train_x = [np.load(file) for file in npy_files]\n",
        "train_x = np.array(train_x)\n",
        "\n",
        "# Load all npy files in the train_y folder\n",
        "npy_files = glob.glob('train_y/*.npy')\n",
        "train_y = [np.load(file) for file in npy_files]\n",
        "train_y = np.array(train_y)\n",
        "\n",
        "\n",
        "# Reshape train_x and train_y to include channel dimension\n",
        "train_x = train_x[..., np.newaxis]\n",
        "train_y = train_y[..., np.newaxis]\n",
        "\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_x, train_y, epochs=10, batch_size=32)\n",
        "\n",
        "\n",
        "# Save the model\n",
        "model.save('trained_model.h5')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
